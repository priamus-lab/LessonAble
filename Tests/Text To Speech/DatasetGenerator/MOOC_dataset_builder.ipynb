{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MOOC dataset builder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXbf-y6j7jx9"
      },
      "source": [
        "**Setup installations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1rImJ3Str8Y"
      },
      "source": [
        "pip install pydub ffmpeg moviepy num2words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n3MG6ld-Y1N"
      },
      "source": [
        "**Google Drive Usage --> Just load your RAW dataset in your drive.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sZTcZik8tpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ed22495-b750-4966-e319-e512eb97c926"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc87oamA-njA"
      },
      "source": [
        "**Value Definitions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDIc7RKl-lzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61ee4281-82ad-4eb3-9eec-d9af30c587ec"
      },
      "source": [
        "author = input('Add the author name which is talking in the audios (i.e ciro_sannino): ') #'carlo_sansone'\n",
        "language = input('Enter the language (2 characters, i.e \"it\") used in the audio / video: ') #'it'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Add the author name which is talking in the audios (i.e ciro_sannino): carlo_sansone\n",
            "Enter the language (2 characters, i.e \"it\") used in the audio / video: it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsNIhTnDA3sH"
      },
      "source": [
        "**Set the row dataset path and where we have to save your new dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_ggsMoLgUMC"
      },
      "source": [
        "# https://drive.google.com/drive/folders/1bYPnqfjuvoqgaknqbwTFhW_ULHOQifkP?usp=sharing \n",
        "# sansone raw dataset\n",
        "raw_dataset_url = '/content/drive/My Drive/sansone_dataset/' # get your raw dataset link from drive and paste it here\n",
        "output_dataset_path = '/content/drive/My Drive/output_dataset/' # set where we should save the new dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZrTQn1PB3Tr"
      },
      "source": [
        "**Creating the directories**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfW6_-s8B4P7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8342956d-9acb-4e7b-a3f4-4dc7d46750c8"
      },
      "source": [
        "author_path =  output_dataset_path + author\n",
        "wavs_path = output_dataset_path + author + '/wavs/'\n",
        "!mkdir '$output_dataset_path'\n",
        "!mkdir '$author_path'\n",
        "!mkdir '$wavs_path'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/My Drive/output_dataset/’: File exists\n",
            "mkdir: cannot create directory ‘/content/drive/My Drive/output_dataset/carlo_sansone’: File exists\n",
            "mkdir: cannot create directory ‘/content/drive/My Drive/output_dataset/carlo_sansone/wavs/’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "813lGi357cym"
      },
      "source": [
        "**Class Definitions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzrpTqTn7LZB"
      },
      "source": [
        "import re\n",
        "from pydub import AudioSegment\n",
        "\n",
        "class SentenceAudioObject:\n",
        "  author = ''\n",
        "  lesson = ''\n",
        "  index = 0\n",
        "  sentence = \"\"\n",
        "  startTime = 0\n",
        "  endTime = 0\n",
        "\n",
        "  def __init__(self, author, lesson, index, sentence, startTime, endTime):\n",
        "        self.author = author\n",
        "        self.lesson = lesson\n",
        "        self.index = index\n",
        "        self.sentence = sentence\n",
        "        self.startTime = startTime\n",
        "        self.endTime = endTime\n",
        "  \n",
        "  def writeAudioSentence(self, destination):\n",
        "        t1 = float(self.startTime) * 1000\n",
        "        t2 = float(self.endTime) * 1000\n",
        "        newAudio = AudioSegment.from_wav('audio.wav',)\n",
        "        newAudio = newAudio[t1:t2]\n",
        "        newAudio = newAudio.set_frame_rate(22050)\n",
        "        newAudio = newAudio.set_channels(1)\n",
        "        return newAudio.export(destination + self.getAudioTitle() + '.wav', format=\"wav\")\n",
        "  \n",
        "  def getAudioTitle(self):\n",
        "    return self.lesson + \"_\" + str(self.index)\n",
        "\n",
        "  def debugPrint(self):\n",
        "      print(\"Sentence: \" + self.sentence + \"\\n\" \n",
        "            + \"start time: \" + self.startTime + \"\\n\"\n",
        "            + \"end time: \" + self.endTime)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnJvt1cJIShh"
      },
      "source": [
        "import moviepy.editor as mp\n",
        "import subprocess\n",
        "\n",
        "def extractAudio(videoName):\n",
        "    subprocess.run( #converts the webm to wav using ffmpeg\n",
        "        (['ffmpeg', '-y', '-i', videoName, 'audio.wav']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPPNfJnS7rsc"
      },
      "source": [
        "import num2words\n",
        "from datetime import datetime\n",
        "\n",
        "def is_number(s): # determines if input is a number or not\n",
        "    if s.lower() == 'nan':\n",
        "      return False\n",
        "    else:\n",
        "      try:\n",
        "        float(s)\n",
        "        return True\n",
        "      except ValueError:\n",
        "        return False\n",
        "    \n",
        "\n",
        "def textnum2str(text, language): # converts a sentence containing numbers to a sentence with those numbers converted to strings\n",
        "    strarr = text.split()\n",
        "    for i in range(len(strarr)):\n",
        "        if is_number(strarr[i]):\n",
        "            strarr[i] = num2words.num2words(float(strarr[i]), lang=language)\n",
        "    formatted = \"\"\n",
        "    for str in strarr:\n",
        "        formatted = formatted + str + \" \"\n",
        "    return formatted\n",
        "\n",
        "def timeStringToSeconds(timeString):\n",
        "  date_time = datetime.strptime(timeString.rstrip().lstrip(), \"%H:%M:%S,%f\")\n",
        "  a_timedelta = date_time - datetime(1900, 1, 1)\n",
        "  seconds = a_timedelta.total_seconds()\n",
        "  return seconds\n",
        "\n",
        "def getSentenceObjects(filename, lesson_name, starting_count):\n",
        "    file = open( filename, \"r\")\n",
        "    lines = file.readlines()\n",
        "    file.close()\n",
        "\n",
        "    non_empty_lines = [line for line in lines if line.rstrip().lstrip() != \"\"]\n",
        "    tmpArraySentenceObj = []\n",
        "    arrayOfFinalSentencesObject = []\n",
        "\n",
        "    count = starting_count\n",
        "    for (index,line) in enumerate(non_empty_lines):\n",
        "\n",
        "      if (line.strip().isdecimal() and index != len(non_empty_lines)-1):\n",
        "        firstSentence = non_empty_lines[index+2].strip()\n",
        "        secondSentence = ''\n",
        "        if index + 3 < len(non_empty_lines) and non_empty_lines[index+3].strip().isdecimal() == False:\n",
        "          secondSentence = non_empty_lines[index+3].strip()\n",
        "        times = (non_empty_lines[index+1].strip()).split('-->')\n",
        "        startTime = str(timeStringToSeconds(times[0]))\n",
        "        endTime = str(timeStringToSeconds(times[1]))\n",
        "        tmp_obj = SentenceAudioObject(author, lesson_name, index, firstSentence.strip() + \" \" + secondSentence.strip(), startTime, endTime)\n",
        "        tmpArraySentenceObj.append(tmp_obj)\n",
        "\n",
        "        if ((secondSentence.rstrip().endswith('.') or secondSentence.rstrip().endswith('?')) or (secondSentence == '' and (firstSentence.rstrip().endswith('.') or firstSentence.rstrip().endswith('?')))):\n",
        "          final_sentence = ' '.join([x.sentence for x in tmpArraySentenceObj])\n",
        "          final_obj = SentenceAudioObject(author, lesson_name, count, final_sentence, tmpArraySentenceObj[0].startTime, tmpArraySentenceObj[len(tmpArraySentenceObj) - 1].endTime)\n",
        "          count += 1\n",
        "          tmpArraySentenceObj = []\n",
        "          arrayOfFinalSentencesObject.append(final_obj)\n",
        "\n",
        "    return arrayOfFinalSentencesObject\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKT2psQGCEjp"
      },
      "source": [
        "**Defining the function that will produce our LJSpeechDataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soeww_AIpm6X",
        "cellView": "code"
      },
      "source": [
        "import os\n",
        "\n",
        "def exportLJSpeechDataset(raw_dataset_url, author_path): # an output folder called 'wavs' and a 'metadata.csv' file will be generated\n",
        "  f = open(author_path + \"/filelists\" + \".txt\", \"w\", encoding=\"utf-8\")\n",
        "  for root, subdirectories, files in os.walk(raw_dataset_url):\n",
        "    for subdirectory in subdirectories:\n",
        "      wavs_count = 0\n",
        "      #initialize variables\n",
        "      subtitle_objects = []\n",
        "      print('\\n Processing ' + subdirectory + ' directory...')\n",
        "      for filename in os.listdir(raw_dataset_url + subdirectory):\n",
        "        # get the mp4 and get its audio as .wav file. Saving this audio as 'audio.wav'\n",
        "        if filename.lower().endswith('.mp4'):\n",
        "          extractAudio(root+subdirectory+ '/'+filename)\n",
        "        # get the .srt file and getting the SentenceObjects.\n",
        "        if filename.lower().endswith('.srt'):\n",
        "          subtitle_objects = getSentenceObjects(root+subdirectory+'/'+filename, subdirectory, wavs_count)\n",
        "          wavs_count += (len(subtitle_objects)-1)\n",
        "      # for each subtitle_object generated we cut the extracted audio in the interval (startTime-->EndTime) \n",
        "      # and write the output audio in the wavs_path. Adding also the informations of the output audio in the .csv file\n",
        "      for obj in subtitle_objects:\n",
        "        filename = obj.getAudioTitle()\n",
        "        ext = '.wav'\n",
        "        sentence = obj.sentence\n",
        "        formattedSentence = textnum2str(sentence, language)\n",
        "        f.write('wavs/' + filename + ext + '|' + formattedSentence + '\\n')\n",
        "        obj.writeAudioSentence(wavs_path)\n",
        "  os.remove('audio.wav')\n",
        "  f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM3FX0FQIR7R",
        "outputId": "7139d48b-a045-4b0c-e40e-a2e9ea8d7c42"
      },
      "source": [
        "exportLJSpeechDataset(raw_dataset_url, author_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Processing lesson-1-week-1-intro directory...\n",
            "\n",
            " Processing classificazione-predizione-numerica-clustering-intro directory...\n",
            "\n",
            " Processing week-1-lesson-3-intro-alternativa directory...\n",
            "\n",
            " Processing classificazione-predizione-numerica-clustering-recap directory...\n",
            "\n",
            " Processing knowledge-transfer-intro directory...\n",
            "\n",
            " Processing week-1-lesson-2-tips-parte1 directory...\n",
            "\n",
            " Processing week-1-lesson-2-intro directory...\n",
            "\n",
            " Processing knowledge-transfer-recap directory...\n",
            "\n",
            " Processing lesson-1-week-1-recap-and-tip-parte-1 directory...\n",
            "\n",
            " Processing Dal-percetrone-al-deep-learning-recap directory...\n",
            "\n",
            " Processing week-3-lesson-2-intro directory...\n",
            "\n",
            " Processing week-1-lesson-3-irecap-tips directory...\n",
            "\n",
            " Processing week-2-lesson-2-intro-parte-1 directory...\n",
            "\n",
            " Processing week-0-parte-1-2 directory...\n",
            "\n",
            " Processing week-4-lesson-1-intro-parte-1 directory...\n",
            "\n",
            " Processing week-3-lesson-1-intro directory...\n",
            "\n",
            " Processing week-2-lesson-2-recap-tips-parte-1 directory...\n",
            "\n",
            " Processing week-2-lesson-1-intro directory...\n",
            "\n",
            " Processing week-3-lesson-2-recap-tips-parte-1 directory...\n",
            "\n",
            " Processing week-3-lesson-1-recap-tips-parte-1 directory...\n",
            "\n",
            " Processing week-4-lesson-2-recap-tips-parte-1 directory...\n",
            "\n",
            " Processing week-4-lesson-2-intro-parte-1 directory...\n",
            "\n",
            " Processing week-5 directory...\n"
          ]
        }
      ]
    }
  ]
}